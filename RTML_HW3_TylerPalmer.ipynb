{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-U6i-i4oX9y5"
      },
      "outputs": [],
      "source": [
        "# Tyler Palmer\n",
        "# Student ID: 801058786\n",
        "# Github: https://github.com/TPal49\n",
        "# Homework 3\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d85ea812714744f798f90914df8b94ee",
            "9fbffb1ac12245b0aba08876684d243a",
            "41d058596f064fcc81868ab4beebc75c",
            "fb4a15f2bbbf4810b287ee7f77f1af76",
            "0cb99e2e7b434de79f1561a781782d48",
            "173e97e693714776a0422263909c2490",
            "56c5c102aca1424e899d88b2f215d7df",
            "f1baeb2fae7f4848b9ee6a64f7273190",
            "08451330d4724c74b079154bb3c5ea15",
            "fb5efd5f5f9d45d0ae448f8ade9c3607",
            "442e01c3073842d2a4ea2ee5459bde5b"
          ]
        },
        "id": "1U74XxeuY71f",
        "outputId": "358c098c-563d-426c-ac42-aadf01dfa881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d85ea812714744f798f90914df8b94ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
        "test = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p30I7TwZnvY",
        "outputId": "0026cb16-cedf-4f96-b199-e776e743c4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0-beta0\n",
            "  Downloading d2l-1.0.0b0-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-beta0) (1.3.5)\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.9.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-beta0) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-beta0) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-beta0) (3.5.3)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-beta0) (2.25.1)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.21.0->d2l==1.0.0-beta0) (2.2.1)\n",
            "Collecting linear-operator>=0.2.0\n",
            "  Downloading linear_operator-0.3.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from gpytorch->d2l==1.0.0-beta0) (1.2.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-beta0) (5.3.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-beta0) (6.3.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-beta0) (6.1.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-beta0) (7.7.1)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-beta0) (6.5.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-beta0) (23.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.8/dist-packages (from matplotlib-inline->d2l==1.0.0-beta0) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->d2l==1.0.0-beta0) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-beta0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-beta0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-beta0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-beta0) (4.0.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from linear-operator>=0.2.0->gpytorch->d2l==1.0.0-beta0) (1.13.1+cu116)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->d2l==1.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-beta0) (6.2)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-beta0) (7.9.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-beta0) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-beta0) (3.6.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-beta0) (3.0.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter->d2l==1.0.0-beta0) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter->d2l==1.0.0-beta0) (2.6.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (4.9.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (2.1.2)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (5.7.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (6.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (3.1.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (1.5.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (0.7.2)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (1.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (5.2.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-beta0) (0.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-beta0) (21.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-beta0) (0.16.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-beta0) (23.2.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-beta0) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-beta0) (1.8.0)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->gpytorch->d2l==1.0.0-beta0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->gpytorch->d2l==1.0.0-beta0) (3.1.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-beta0) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-beta0) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-beta0) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->d2l==1.0.0-beta0) (3.0.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-beta0) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-beta0) (2.16.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l==1.0.0-beta0) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook->jupyter->d2l==1.0.0-beta0) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0-beta0) (4.5.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook->jupyter->d2l==1.0.0-beta0) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter->d2l==1.0.0-beta0) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-beta0) (0.8.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-beta0) (5.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-beta0) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-beta0) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0-beta0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0-beta0) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-beta0) (3.15.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616822 sha256=dca367f36cec5229c252f05a0f71bdca7b5960026bb1525f37ce5cfb3e1d2473\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/6d/b3/a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n",
            "Successfully built gym\n",
            "Installing collected packages: qtpy, matplotlib-inline, jedi, gym, linear-operator, gpytorch, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed d2l-1.0.0b0 gpytorch-1.9.1 gym-0.21.0 jedi-0.18.2 jupyter-1.0.0 linear-operator-0.3.0 matplotlib-inline-0.1.6 qtconsole-5.4.0 qtpy-2.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.6.9.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from ptflops) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->ptflops) (4.5.0)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.9-py3-none-any.whl size=11712 sha256=93eed51f999cb45c0c126f6e1341f858a0ab36eb03b0545eef5f6514c862a223\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/86/d5/cf62a3571b005f91cd9accefc5e10f40214538be997198afad\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.6.9\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-beta0\n",
        "!pip install ptflops\n",
        "from d2l import torch as d2l\n",
        "d2l.use_svg_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lRpZ-wr7Z0FH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def vgg_block(num_convs, out_channels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
        "        layers.append(nn.LazyBatchNorm2d())\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class VGG(d2l.Classifier):\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        conv_blks = []\n",
        "        for (num_convs, out_channels) in arch:\n",
        "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
        "        self.net = nn.Sequential(\n",
        "            *conv_blks, nn.Flatten(),\n",
        "            nn.LazyLinear(256), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(256), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrxzYaADd4A9",
        "outputId": "4997d410-84bc-4eaa-f08d-062c9c26d818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data/',train=True,download=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=128,shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True,transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=128,shuffle=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1JC4NrFK9pT"
      },
      "source": [
        "question 1 - vgg11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fKD8kP4aL4q",
        "outputId": "b058e9c8-3301-4064-da69-01b494014b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  75.49\n",
            "Model accuracy on validation:  71.86\n",
            "Model Loss:  0.9253934025764465\n"
          ]
        }
      ],
      "source": [
        "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 64), (2, 32))) # VGG 11\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.1, momentum = 0.9)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew21YwihLAgT"
      },
      "source": [
        "question 1 - vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bOg0gPeucme",
        "outputId": "6db806a7-5717-4cb0-f4bb-a1cd1b97e132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  75.484\n",
            "Model accuracy on validation:  71.78\n",
            "Model Loss:  1.0784943103790283\n"
          ]
        }
      ],
      "source": [
        "model2 = VGG(arch=((2, 16), (2, 32), (3, 64), (3, 128), (3, 128)), lr=0.1) # VGG 16\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model2.parameters(), lr=0.1)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHWLMF9TLDrI"
      },
      "source": [
        "question 1  - vgg19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvzjsR5Jue3d",
        "outputId": "d83afb19-e8d5-454d-aead-c12c0b66a4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  57.01199999999999\n",
            "Model accuracy on validation:  55.76\n",
            "Model Loss:  1.1473625898361206\n"
          ]
        }
      ],
      "source": [
        "model = VGG(arch=((2, 16), (2, 32), (4, 64), (4, 128), (4, 128))) # VGG 19\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.1, momentum = 0.9)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k71NzJYxLHAV"
      },
      "source": [
        "question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PPBIOye5LXyg"
      },
      "outputs": [],
      "source": [
        "class Inception(nn.Module):\n",
        "    # c1--c4 are the number of output channels for each branch\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        # Branch 1\n",
        "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
        "        # Branch 2\n",
        "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
        "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
        "        # Branch 3\n",
        "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
        "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
        "        # Branch 4\n",
        "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = F.relu(self.b1_1(x))\n",
        "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
        "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
        "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
        "        return torch.cat((b1, b2, b3, b4), dim=1)\n",
        "\n",
        "class GoogleNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "        \n",
        "@d2l.add_to_class(GoogleNet)\n",
        "def b2(self):\n",
        "  return nn.Sequential(\n",
        "      nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
        "      nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  \n",
        "@d2l.add_to_class(GoogleNet)\n",
        "def b3(self):\n",
        "    return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                         Inception(128, (128, 192), (32, 96), 64),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  \n",
        "@d2l.add_to_class(GoogleNet)\n",
        "def b4(self):\n",
        "    return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "\n",
        "@d2l.add_to_class(GoogleNet)\n",
        "def b5(self):\n",
        "    return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                         nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
        "    \n",
        "@d2l.add_to_class(GoogleNet)\n",
        "def __init__(self, lr=0.1, num_classes=10):\n",
        "    super(GoogleNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                             self.b5(), nn.LazyLinear(num_classes))\n",
        "    self.net.apply(d2l.init_cnn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcF3vrD7MYCx",
        "outputId": "56a1ccb5-8b9f-452e-e7a7-3836975ef94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  66.266\n",
            "Model accuracy on validation:  63.349999999999994\n",
            "Model Loss:  1.197005271911621\n"
          ]
        }
      ],
      "source": [
        "model = GoogleNet(lr=0.1)\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.1, momentum = 0.9)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFbt2MP8IbYt"
      },
      "source": [
        "Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nrlRsXSPIYE4"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):  \n",
        "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                                   stride=strides)\n",
        "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)\n",
        "\n",
        "class ResNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "        \n",
        "@d2l.add_to_class(ResNet)\n",
        "def block(self, num_residuals, num_channels, first_block=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i == 0 and not first_block:\n",
        "            blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(Residual(num_channels))\n",
        "    return nn.Sequential(*blk)\n",
        "\n",
        "@d2l.add_to_class(ResNet)\n",
        "def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1())\n",
        "    for i, b in enumerate(arch):\n",
        "        self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "    self.net.add_module('last', nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxSxVLe0JBRf",
        "outputId": "ad8eba59-b809-4be3-bdea-fbce855379dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  81.54400000000001\n",
            "Model accuracy on validation:  72.83\n",
            "Model Loss:  0.641405463218689\n"
          ]
        }
      ],
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
        "                       lr, num_classes)\n",
        "\n",
        "model = ResNet18(lr=0.01)\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.01, momentum = 0.9)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-DQu5LYJBpI",
        "outputId": "1b2bd549-d811-4828-c88b-407229d25698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  60.3\n",
            "Model accuracy on validation:  58.050000000000004\n",
            "Model Loss:  1.1516716480255127\n"
          ]
        }
      ],
      "source": [
        "class ResNet26(ResNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128),(2, 128),(2, 128), (2, 256), (2, 512)),\n",
        "                       lr, num_classes)\n",
        "\n",
        "model = ResNet26(lr=0.01)\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.01, momentum = 0.9)\n",
        "epochs = 2\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2kizllWJUxv",
        "outputId": "1433999d-d0f8-46a7-b0b0-8376b5b717b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training.\n",
            "Model accuracy on train:  53.886\n",
            "Model accuracy on validation:  52.470000000000006\n",
            "Model Loss:  1.4039490222930908\n"
          ]
        }
      ],
      "source": [
        "class ResNet32(ResNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128),(2, 128),(2, 128),(2, 128),(2, 128), (1, 256), (1, 512)),\n",
        "                       lr, num_classes)\n",
        "\n",
        "model = ResNet32(lr=0.01)\n",
        "lossFunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.01, momentum = 0.9)\n",
        "epochs = 2\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunct(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss = loss.item()\n",
        "            \n",
        "\n",
        "print('Finished Training.')\n",
        "\n",
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "val_total_correct = 0\n",
        "val_total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        val_total_images += labels.size(0)\n",
        "        val_total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "val_model_accuracy = val_total_correct/ val_total_images * 100\n",
        "print(\"Model accuracy on train: \", model_accuracy)\n",
        "print(\"Model accuracy on validation: \", val_model_accuracy)\n",
        "print(\"Model Loss: \", running_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d85ea812714744f798f90914df8b94ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fbffb1ac12245b0aba08876684d243a",
              "IPY_MODEL_41d058596f064fcc81868ab4beebc75c",
              "IPY_MODEL_fb4a15f2bbbf4810b287ee7f77f1af76"
            ],
            "layout": "IPY_MODEL_0cb99e2e7b434de79f1561a781782d48"
          }
        },
        "9fbffb1ac12245b0aba08876684d243a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173e97e693714776a0422263909c2490",
            "placeholder": "​",
            "style": "IPY_MODEL_56c5c102aca1424e899d88b2f215d7df",
            "value": "100%"
          }
        },
        "41d058596f064fcc81868ab4beebc75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1baeb2fae7f4848b9ee6a64f7273190",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08451330d4724c74b079154bb3c5ea15",
            "value": 170498071
          }
        },
        "fb4a15f2bbbf4810b287ee7f77f1af76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5efd5f5f9d45d0ae448f8ade9c3607",
            "placeholder": "​",
            "style": "IPY_MODEL_442e01c3073842d2a4ea2ee5459bde5b",
            "value": " 170498071/170498071 [00:01&lt;00:00, 100203605.53it/s]"
          }
        },
        "0cb99e2e7b434de79f1561a781782d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173e97e693714776a0422263909c2490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c5c102aca1424e899d88b2f215d7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1baeb2fae7f4848b9ee6a64f7273190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08451330d4724c74b079154bb3c5ea15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb5efd5f5f9d45d0ae448f8ade9c3607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442e01c3073842d2a4ea2ee5459bde5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}